{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mock Data Generation and Data Preparation for ingestion in Neo4j\n",
    "---\n",
    "\n",
    "The mock data is generated using simple and humble tools like Excel, and some creative help from the internet ([Mockaroo](https://mockaroo.com/)).\n",
    "\n",
    "The data resembles material consumption for a Job/Work Order, projected on a exploded BOM-like structure. The data is exported to CSV format and stored in the `data` directory.\n",
    "\n",
    "This data is then converted into separate CSV files to ingest into Neo4j database using humble Python and pandas magic. The data is stored in the `data/neo4j` directory. The list of CSV files are:\n",
    "1. items.csv `(:item)`\n",
    "2. lots.csv `(:lot)`\n",
    "3. jobs.csv `(:job)`\n",
    "4. item_belongs_to_lot.csv `(:item)-[:BELONGS_TO]->(:lot)`\n",
    "5. lot_consumed_by_job.csv `(:lot)-[:CONSUMED_BY]->(:job)`\n",
    "6. job_produces_lot.csv `(:job)-[:PRODUCES]->(:lot)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required libraries\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# setting the home directory\n",
    "path_home = Path('..')\n",
    "path_export = path_home / 'data' / 'neo4j'\n",
    "os.mkdir(path_export) if not os.path.exists(path_export) else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 674 entries, 0 to 673\n",
      "Data columns (total 32 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   L1_ItemNumber       674 non-null    object\n",
      " 1   L1_ItemDescription  674 non-null    object\n",
      " 2   L1_ItemType         674 non-null    object\n",
      " 3   L1_LotNumber        674 non-null    object\n",
      " 4   L1_Job              674 non-null    object\n",
      " 5   L1_JobStatus        674 non-null    object\n",
      " 6   L2_Quantity         674 non-null    int64 \n",
      " 7   L2_ItemNumber       674 non-null    object\n",
      " 8   L2_ItemDescription  674 non-null    object\n",
      " 9   L2_ItemType         674 non-null    object\n",
      " 10  L2_LotNumber        674 non-null    object\n",
      " 11  L2_Job              674 non-null    object\n",
      " 12  L2_JobStatus        674 non-null    object\n",
      " 13  L3_Quantity         674 non-null    int64 \n",
      " 14  L3_ItemNumber       674 non-null    object\n",
      " 15  L3_ItemDescription  674 non-null    object\n",
      " 16  L3_ItemType         674 non-null    object\n",
      " 17  L3_LotNumber        674 non-null    object\n",
      " 18  L3_Job              674 non-null    object\n",
      " 19  L3_JobStatus        674 non-null    object\n",
      " 20  L4_Quantity         674 non-null    int64 \n",
      " 21  L4_ItemNumber       674 non-null    object\n",
      " 22  L4_ItemDescription  674 non-null    object\n",
      " 23  L4_ItemType         674 non-null    object\n",
      " 24  L4_LotNumber        674 non-null    object\n",
      " 25  L4_Job              674 non-null    object\n",
      " 26  L4_JobStatus        674 non-null    object\n",
      " 27  L5_Quantity         674 non-null    int64 \n",
      " 28  L5_ItemNumber       674 non-null    object\n",
      " 29  L5_ItemDescription  674 non-null    object\n",
      " 30  L5_ItemType         674 non-null    object\n",
      " 31  L5_LotNumber        674 non-null    object\n",
      "dtypes: int64(4), object(28)\n",
      "memory usage: 168.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df_raw = pd.read_csv(path_home / 'data' / 'data.csv')\n",
    "df_raw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNodeDF(df, cols, levels):\n",
    "    \"\"\"\n",
    "    This function takes a dataframe and returns a new dataframe with unique values for the speciied cols and levels.\n",
    "    \"\"\"\n",
    "    newcols_item = cols\n",
    "    list_df_items = []\n",
    "    \n",
    "    for LEVEL in levels:\n",
    "        oldcols_item = [f'L{str(LEVEL)}_{col}' for col in newcols_item]\n",
    "        \n",
    "        list_df_items.append(\n",
    "            df_raw \\\n",
    "                .loc[:, oldcols_item] \\\n",
    "                .rename(columns=dict(zip(oldcols_item, newcols_item)))\n",
    "        )\n",
    "    \n",
    "    return pd.concat(list_df_items, ignore_index=True) \\\n",
    "        .drop_duplicates() \\\n",
    "        .reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Node Data\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### (:Item)\n",
    "| item_number | item_description | item_type |\n",
    "|-------------|------------------|-----------|\n",
    "\n",
    "---\n",
    "\n",
    "- To extract item details, the ItemNumber, ItemDescription, and ItemType fields are concatenated (L1, L2, L3, L4, L5 levels)\n",
    "- unique values of (ItemNumber, ItemDescription, ItemType) are extracted\n",
    "- The unique values are stored in the `items.csv` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 875 entries, 0 to 874\n",
      "Data columns (total 3 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   ItemNumber       875 non-null    object\n",
      " 1   ItemDescription  875 non-null    object\n",
      " 2   ItemType         875 non-null    object\n",
      "dtypes: object(3)\n",
      "memory usage: 20.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df_item = getNodeDF(\n",
    "    df      = df_raw,\n",
    "    cols    = ['ItemNumber', 'ItemDescription', 'ItemType',],\n",
    "    levels  = [1, 2, 3, 4, 5]\n",
    ")\n",
    "df_item.to_csv(path_export / 'item.csv', index=False)\n",
    "df_item.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (:Lot)\n",
    "| ItemNumber | LotNumber |\n",
    "|------------|-----------|\n",
    "\n",
    "---\n",
    "\n",
    "- To extract lot details, the ItemNumber, LotNumber fields are concatenated (L1, L2, L3, L4, L5 levels)\n",
    "- unique values of (ItemNumber, LotNumber) are extracted\n",
    "- The unique values are stored in the `lots.csv` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3370 entries, 0 to 3369\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   ItemNumber  3370 non-null   object\n",
      " 1   LotNumber   3370 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 52.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df_lot = getNodeDF(\n",
    "    df      = df_raw,\n",
    "    cols    = ['ItemNumber', 'LotNumber',],\n",
    "    levels  = [1, 2, 3, 4, 5]\n",
    ")\n",
    "df_lot.to_csv(path_export / 'lot.csv', index=False)\n",
    "df_lot.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (:Job)\n",
    "| Job | JobStatus |\n",
    "|-----|-----------|\n",
    "\n",
    "---\n",
    "\n",
    "- To extract job details, the Job, JobStatus fields are concatenated (L1, L2, L3, L4, L5 levels)\n",
    "- unique values of (Job, JobStatus) are extracted\n",
    "- The unique values are stored in the `jobs.csv` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2121 entries, 0 to 2120\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   Job        2121 non-null   object\n",
      " 1   JobStatus  2121 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 33.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df_job = getNodeDF(\n",
    "    df      = df_raw,\n",
    "    cols    = ['Job', 'JobStatus',],\n",
    "    levels  = [1, 2, 3, 4]\n",
    ")\n",
    "df_job.to_csv(path_export / 'job.csv', index=False)\n",
    "df_job.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Edge Data\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEdgeDF(df, cols, levels, adds):\n",
    "    \"\"\"\n",
    "    This function takes a dataframe and returns a new dataframe with unique values for the speciied cols and levels.\n",
    "    \"\"\"\n",
    "    newcols_item = cols\n",
    "    list_df_items = []\n",
    "    \n",
    "    for LEVEL in levels:\n",
    "        oldcols_item = [f'L{str(LEVEL+add)}_{col}' for col,add in zip(newcols_item, adds)]\n",
    "        \n",
    "        list_df_items.append(\n",
    "            df_raw \\\n",
    "                .loc[:, oldcols_item] \\\n",
    "                .rename(columns=dict(zip(oldcols_item, newcols_item)))\n",
    "        )\n",
    "    \n",
    "    return pd.concat(list_df_items, ignore_index=True) \\\n",
    "        .drop_duplicates() \\\n",
    "        .reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (:Item)-[:BELONGS_TO]->(:Lot)\n",
    "| ItemNumber | LotNumber |\n",
    "|------------|-----------|\n",
    "\n",
    "---\n",
    "\n",
    "- To extract the relationship between Item and Lot, the ItemNumber, LotNumber fields are concatenated (L1, L2, L3, L4, L5 levels)\n",
    "- unique values of (ItemNumber, LotNumber) are extracted\n",
    "- The unique values are stored in the `item_belongs_to_lot.csv` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3370 entries, 0 to 3369\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   ItemNumber  3370 non-null   object\n",
      " 1   LotNumber   3370 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 52.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df_item_belongs_to_lot = getEdgeDF(\n",
    "    df      = df_raw,\n",
    "    cols    = ['ItemNumber', 'LotNumber',],\n",
    "    levels  = [1, 2, 3, 4, 5],\n",
    "    adds    = [0, 0]\n",
    ")\n",
    "df_item_belongs_to_lot.to_csv(path_export / 'item_belongs_to_lot.csv', index=False)\n",
    "df_item_belongs_to_lot.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (:Lot)-[:CONSUMED_BY]->(:Job)\n",
    "| ItemNumber | LotNumber | Job | Quantity |\n",
    "|------------|-----------|-----|----------|\n",
    "\n",
    "---\n",
    "\n",
    "- To extract the relationship between Lot and Job, the (L)ItemNumber, (L)LotNumber, (L+1)Job, (L)Quantity fields are concatenated (L1, L2, L3, L4, L5 levels)\n",
    "- unique values of (ItemNumber, LotNumber, Job, Quantity) are extracted\n",
    "- The unique values are stored in the `lot_consumed_by_job.csv` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2696 entries, 0 to 2695\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   ItemNumber  2696 non-null   object\n",
      " 1   LotNumber   2696 non-null   object\n",
      " 2   Job         2696 non-null   object\n",
      " 3   Quantity    2696 non-null   int64 \n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 84.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df_lot_consumed_by_job = getEdgeDF(\n",
    "    df      = df_raw,\n",
    "    cols    = ['ItemNumber', 'LotNumber', 'Job', 'Quantity'],\n",
    "    levels  = [1, 2, 3, 4],\n",
    "    adds    = [1, 1, 0, 1]\n",
    ")\n",
    "df_lot_consumed_by_job.to_csv(path_export / 'lot_consumed_by_job.csv', index=False)\n",
    "df_lot_consumed_by_job.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (:Job)-[:PRODUCES]->(:Lot)\n",
    "| Job | ItemNumber | LotNumber |\n",
    "|-----|------------|-----------|\n",
    "\n",
    "---\n",
    "\n",
    "- To extract the relationship between Job and Lot, the (L)Job, (L)ItemNumber, (L)LotNumber fields are concatenated (L1, L2, L3, L4, L5 levels)\n",
    "- unique values of (Job, ItemNumber, LotNumber) are extracted\n",
    "- The unique values are stored in the `job_produces_lot.csv` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2696 entries, 0 to 2695\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Job         2696 non-null   object\n",
      " 1   ItemNumber  2696 non-null   object\n",
      " 2   LotNumber   2696 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 63.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df_job_produces_lot = getEdgeDF(\n",
    "    df      = df_raw,\n",
    "    cols    = ['Job', 'ItemNumber', 'LotNumber'],\n",
    "    levels  = [1, 2, 3, 4],\n",
    "    adds    = [0, 0, 0]\n",
    ")\n",
    "df_job_produces_lot.to_csv(path_export / 'job_produces_lot.csv', index=False)\n",
    "df_job_produces_lot.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-science",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
